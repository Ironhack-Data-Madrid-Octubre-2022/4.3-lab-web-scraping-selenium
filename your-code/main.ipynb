{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Lab\n",
    "\n",
    "You will find in this notebook some scrapy exercises to practise your scraping skills.\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- Check the response status code for each request to ensure you have obtained the intended contennt.\n",
    "- Print the response text in each request to understand the kind of info you are getting and its format.\n",
    "- Check for patterns in the response text to extract the data/info requested in each question.\n",
    "- Visit each url and take a look at its source through Chrome DevTools. You'll need to identify the html tags, special class names etc. used for the html content you are expected to extract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Selenium Doc](https://www.selenium.dev/documentation/)\n",
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide) documentation \n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [lxml lib](https://lxml.de/)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are the libraries and modules you may need. `Selenium` and `pandas` are imported for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in /opt/anaconda3/envs/clase/lib/python3.7/site-packages (3.8.4)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/clase/lib/python3.7/site-packages (from webdriver-manager) (4.64.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/clase/lib/python3.7/site-packages (from webdriver-manager) (2.28.1)\n",
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/envs/clase/lib/python3.7/site-packages (from webdriver-manager) (0.21.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/clase/lib/python3.7/site-packages (from requests->webdriver-manager) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/anaconda3/envs/clase/lib/python3.7/site-packages (from requests->webdriver-manager) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/envs/clase/lib/python3.7/site-packages (from requests->webdriver-manager) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/clase/lib/python3.7/site-packages (from requests->webdriver-manager) (3.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "PATH=ChromeDriverManager().install()   # instala el driver\n",
    "\n",
    "driver=webdriver.Chrome(PATH)         # abre una pestaña de chrome\n",
    "\n",
    "driver.get('https://www.google.es')     # entra en google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enable the options you may need. In the next cell you have an example of them but you can choose to use them or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver configuration\n",
    "opciones=Options()\n",
    "\n",
    "opciones.add_experimental_option('excludeSwitches', ['enable-automation'])\n",
    "opciones.add_experimental_option('useAutomationExtension', False)\n",
    "opciones.headless=False    # si True, no aperece la ventana (headless=no visible)\n",
    "opciones.add_argument('--start-maximized')         # comienza maximizado\n",
    "#opciones.add_argument('user-data-dir=selenium')    # mantiene las cookies\n",
    "#opciones.add_extension('driver_folder/adblock.crx')       # adblocker\n",
    "opciones.add_argument('--incognito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PATH=ChromeDriverManager().install()   # instala el driver\n",
    "\n",
    "driver = webdriver.Chrome(PATH,options = opciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download, parse, and print the content from the Trending Developers page from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PATH=ChromeDriverManager().install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/developers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(PATH)\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the names of the trending developers retrieved in the previous step.\n",
    "\n",
    "Your output should be a Python list of developer names. Each name should not contain any html tag.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Find out the html tag and class names used for the developer names.\n",
    "\n",
    "1. Use string manipulation techniques to replace whitespaces and linebreaks (i.e. `\\n`) in the *text* of each html element. Use a list to store the clean names.\n",
    "\n",
    "1. Print the list of names.\n",
    "\n",
    "Your output should look like below:\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (神楽坂覚々)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nikita Sobolev'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_element(By.XPATH, '//*[@id=\"pa-sobolevn\"]/div[2]/div[1]/div[1]/h1').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows=driver.find_elements(By.CLASS_NAME,'Box-row')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nombre=rows[0].find_elements(By.TAG_NAME,'a')[2].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alias=rows[0].find_elements(By.TAG_NAME,'a')[3].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nikita Sobolev (sobolevn)',\n",
       " 'Emil Ernerfeldt (emilk)',\n",
       " 'Jonny Borges (jonataslaw)',\n",
       " 'Stephen Celis (stephencelis)',\n",
       " 'monkeyWie (gopeed)',\n",
       " 'Azure SDK Bot (azure-sdk)',\n",
       " 'Martin Bonnin (martinbonnin)',\n",
       " 'Wangchong Zhou (fffonion)',\n",
       " 'Ammar Ahmed (ammarahm-ed)',\n",
       " 'Matt Bierner (mjbvz)',\n",
       " 'Alessandro Ros (aler9)',\n",
       " 'Mike Perham (mperham)',\n",
       " 'DavidKorczynski (Follow)',\n",
       " 'Abhijeet Prasad (AbhiPrasad)',\n",
       " 'Mislav Marohnić (mislav)',\n",
       " 'Leonard Hecker (lhecker)',\n",
       " 'Pedro Cuenca (pcuenca)',\n",
       " 'Marcus Olsson (marcusolsson)',\n",
       " 'Alex Eagle (alexeagle)',\n",
       " 'Nolan Lawson (nolanlawson)',\n",
       " 'Luke Latham (guardrex)',\n",
       " 'Joshua Levy (jlevy)',\n",
       " 'Bas Nijholt (basnijholt)',\n",
       " 'Ice3man (Ice3man543)',\n",
       " 'kunfei (gedoor)']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string=''\n",
    "name_alias=[]\n",
    "\n",
    "for i in rows:\n",
    "    string=i.find_elements(By.TAG_NAME,'a')[2].text +' '+ '(' + i.find_elements(By.TAG_NAME,'a')[3].text +')'\n",
    "    name_alias.append(string)\n",
    "    \n",
    "name_alias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the trending Python repositories in GitHub\n",
    "\n",
    "The steps to solve this problem is similar to the previous one except that you need to find out the repository names instead of developer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/python?since=daily'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(PATH)\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "caja=driver.find_elements(By.CLASS_NAME,'Box-row')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Star'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find=caja[1].find_elements(By.TAG_NAME,'a')[1].text\n",
    "find\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['public-apis / public-apis',\n",
       " 'bregman-arie / devops-exercises',\n",
       " 'facebookresearch / fairseq',\n",
       " 'cloneofsimo / paint-with-words-sd',\n",
       " 'Azure / azure-cli',\n",
       " 'caronc / apprise',\n",
       " 'joweich / chat-miner',\n",
       " 'PaddlePaddle / PaddleTS',\n",
       " 'mli / autocut',\n",
       " 'sczhou / CodeFormer',\n",
       " 'unifyai / ivy',\n",
       " 'augmentedstartups / AS-One',\n",
       " 'loTus04 / W4SP-Stealer',\n",
       " 'rwightman / pytorch-image-models',\n",
       " 'iterativv / NostalgiaForInfinity',\n",
       " 'getredash / redash',\n",
       " 'ethereum / consensus-specs',\n",
       " 'd8ahazard / sd_dreambooth_extension',\n",
       " 'microsoft / recommenders',\n",
       " 'zulip / zulip',\n",
       " 'ultralytics / yolov5',\n",
       " 'openai / improved-diffusion',\n",
       " 'facebookresearch / ParlAI',\n",
       " 'aliyun / surftrace',\n",
       " 'NVlabs / stylegan2-ada-pytorch']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repositories=[]\n",
    "\n",
    "for i in caja:\n",
    "    \n",
    "    r_name=i.find_elements(By.TAG_NAME,'a')[1].text\n",
    "    if r_name != 'Star' :\n",
    "        repositories.append(r_name)\n",
    "    else :\n",
    "        r_name2=i.find_elements(By.TAG_NAME,'a')[2].text\n",
    "        repositories.append(r_name2)\n",
    "    \n",
    "repositories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display all the image links from Walt Disney wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/Walt_Disney'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(PATH)\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "walt=driver.find_elements(By.TAG_NAME,'img')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://upload.wikimedia.org/wikipedia/en/thumb/e/e7/Cscr-featured.svg/20px-Cscr-featured.svg.png\n",
      "https://upload.wikimedia.org/wikipedia/en/thumb/8/8c/Extended-protection-shackle.svg/20px-Extended-protection-shackle.svg.png\n",
      "https://upload.wikimedia.org/wikipedia/commons/thumb/d/df/Walt_Disney_1946.JPG/220px-Walt_Disney_1946.JPG\n",
      "https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Walt_Disney_1942_signature.svg/150px-Walt_Disney_1942_signature.svg.png\n",
      "https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Walt_Disney_Birthplace_Exterior_Hermosa_Chicago_Illinois.jpg/220px-Walt_Disney_Birthplace_Exterior_Hermosa_Chicago_Illinois.jpg\n",
      "https://upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Walt_Disney_envelope_ca._1921.jpg/220px-Walt_Disney_envelope_ca._1921.jpg\n",
      "https://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Trolley_Troubles_poster.jpg/170px-Trolley_Troubles_poster.jpg\n",
      "https://upload.wikimedia.org/wikipedia/en/thumb/4/4e/Steamboat-willie.jpg/170px-Steamboat-willie.jpg\n",
      "https://upload.wikimedia.org/wikipedia/commons/thumb/5/57/Walt_Disney_1935.jpg/170px-Walt_Disney_1935.jpg\n",
      "https://upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg/220px-Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg\n",
      "https://upload.wikimedia.org/wikipedia/commons/thumb/1/15/Disney_drawing_goofy.jpg/170px-Disney_drawing_goofy.jpg\n",
      "https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/WaltDisneyplansDisneylandDec1954.jpg/220px-WaltDisneyplansDisneylandDec1954.jpg\n",
      "https://upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Walt_disney_portrait_right.jpg/170px-Walt_disney_portrait_right.jpg\n",
      "https://upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Walt_Disney_Grave.JPG/170px-Walt_Disney_Grave.JPG\n",
      "https://upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Roy_O._Disney_with_Company_at_Press_Conference.jpg/170px-Roy_O._Disney_with_Company_at_Press_Conference.jpg\n",
      "https://upload.wikimedia.org/wikipedia/commons/thumb/1/13/DisneySchiphol1951.jpg/220px-DisneySchiphol1951.jpg\n",
      "https://upload.wikimedia.org/wikipedia/commons/thumb/6/6c/Disney1968.jpg/170px-Disney1968.jpg\n",
      "https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Disney_Oscar_1953_%28cropped%29.jpg/170px-Disney_Oscar_1953_%28cropped%29.jpg\n",
      "https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/30px-Commons-logo.svg.png\n",
      "https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/38px-Wikisource-logo.svg.png\n",
      "https://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Wikiquote-logo.svg/34px-Wikiquote-logo.svg.png\n",
      "https://upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png\n",
      "https://upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png\n",
      "https://upload.wikimedia.org/wikipedia/commons/thumb/e/e3/Disneyland_Resort_logo.svg/135px-Disneyland_Resort_logo.svg.png\n",
      "https://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Animation_disc.svg/20px-Animation_disc.svg.png\n",
      "https://upload.wikimedia.org/wikipedia/en/thumb/6/69/P_vip.svg/19px-P_vip.svg.png\n",
      "https://upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Magic_Kingdom_castle.jpg/15px-Magic_Kingdom_castle.jpg\n",
      "https://upload.wikimedia.org/wikipedia/en/thumb/e/e7/Video-x-generic.svg/19px-Video-x-generic.svg.png\n",
      "https://upload.wikimedia.org/wikipedia/commons/thumb/a/a3/Flag_of_Los_Angeles_County%2C_California.svg/21px-Flag_of_Los_Angeles_County%2C_California.svg.png\n",
      "https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Blank_television_set.svg/21px-Blank_television_set.svg.png\n",
      "https://upload.wikimedia.org/wikipedia/en/thumb/a/a4/Flag_of_the_United_States.svg/21px-Flag_of_the_United_States.svg.png\n",
      "https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/14px-Commons-logo.svg.png\n",
      "https://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Wikiquote-logo.svg/16px-Wikiquote-logo.svg.png\n",
      "https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/18px-Wikisource-logo.svg.png\n",
      "https://upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Wikidata-logo.svg/21px-Wikidata-logo.svg.png\n",
      "https://upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png\n",
      "https://en.wikipedia.org/static/images/footer/wikimedia-button.png\n",
      "https://en.wikipedia.org/static/images/footer/poweredby_mediawiki_88x31.png\n"
     ]
    }
   ],
   "source": [
    "for i in walt:\n",
    "    image=i.get_attribute('src')\n",
    "    print(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve an arbitary Wikipedia page of \"Python\" and create a list of links on that page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url ='https://en.wikipedia.org/wiki/Python' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(PATH)\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "python=driver.find_elements(By.TAG_NAME,'link')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/w/load.php?lang=en&modules=ext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cskins.vector.styles.legacy%7Cwikibase.client.init&only=styles&skin=vector\n",
      "https://en.wikipedia.org/w/load.php?lang=en&modules=site.styles&only=styles&skin=vector\n",
      "https://upload.wikimedia.org/\n",
      "https://en.m.wikipedia.org/wiki/Python\n",
      "https://en.wikipedia.org/w/index.php?title=Python&action=edit\n",
      "https://en.wikipedia.org/static/apple-touch/wikipedia.png\n",
      "https://en.wikipedia.org/static/favicon/wikipedia.ico\n",
      "https://en.wikipedia.org/w/opensearch_desc.php\n",
      "https://en.wikipedia.org/w/api.php?action=rsd\n",
      "https://creativecommons.org/licenses/by-sa/3.0/\n",
      "https://en.wikipedia.org/wiki/Python\n",
      "https://meta.wikimedia.org/\n",
      "https://login.wikimedia.org/\n"
     ]
    }
   ],
   "source": [
    "for i in python:\n",
    "    link=i.get_attribute('href')\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Titles that have changed in the United States Code since its last release point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'http://uscode.house.gov/download/download.shtml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(PATH)\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "usc=driver.find_elements(By.CLASS_NAME,'usctitlechanged')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title 17 - Copyrights ٭\n",
      "Title 22 - Foreign Relations and Intercourse\n",
      "Title 38 - Veterans' Benefits ٭\n",
      "Title 40 - Public Buildings, Property, and Works ٭\n",
      "Title 41 - Public Contracts ٭\n",
      "Title 42 - The Public Health and Welfare\n",
      "Title 44 - Public Printing and Documents ٭\n",
      "Title 49 - Transportation ٭\n",
      "Title 54 - National Park Service and Related Programs ٭\n"
     ]
    }
   ],
   "source": [
    "for i in usc:\n",
    "    t_c=i.text\n",
    "    print(t_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Python list with the top ten FBI's Most Wanted names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.fbi.gov/wanted/topten'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(PATH)\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbi=driver.find_elements(By.CLASS_NAME,'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST WANTED\n",
      "OMAR ALEXANDER CARDENAS\n",
      "ALEXIS FLORES\n",
      "JOSE RODOLFO VILLARREAL-HERNANDEZ\n",
      "YULAN ADONAY ARCHAGA CARIAS\n",
      "BHADRESHKUMAR CHETANBHAI PATEL\n",
      "ALEJANDRO ROSALES CASTILLO\n",
      "MICHAEL JAMES PRATT\n",
      "RUJA IGNATOVA\n",
      "ARNOLDO JIMENEZ\n",
      "RAFAEL CARO-QUINTERO\n"
     ]
    }
   ],
   "source": [
    "for i in fbi:\n",
    "    names=i.text\n",
    "    print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.emsc-csem.org/Earthquake/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(PATH)\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"5bb64f448e82cc4eaf24b75ad5095a4f\", element=\"ee217259-e74c-4456-8dad-f83fdbd5affd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5bb64f448e82cc4eaf24b75ad5095a4f\", element=\"007a32b4-7174-403b-9f42-0aadb0433c94\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5bb64f448e82cc4eaf24b75ad5095a4f\", element=\"0e0112a2-b4bb-4cdb-839e-89db3d065438\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5bb64f448e82cc4eaf24b75ad5095a4f\", element=\"a28ed2af-56dd-497f-a95a-4a46b332ab23\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5bb64f448e82cc4eaf24b75ad5095a4f\", element=\"b8a7d629-8c2c-4fe6-b950-7354e01b9c61\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5bb64f448e82cc4eaf24b75ad5095a4f\", element=\"76ec9376-55f3-4a80-8655-aba7c001f990\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5bb64f448e82cc4eaf24b75ad5095a4f\", element=\"6db5c5d3-1977-41f9-b9af-9fc99d0437ac\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5bb64f448e82cc4eaf24b75ad5095a4f\", element=\"5c4bea99-d93e-4b17-9ce8-7997b7db728d\")>]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col=driver.find_elements(By.CLASS_NAME,'th2')\n",
    "col\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date & Time UTC',\n",
       " 'Latitude degrees',\n",
       " 'Longitude degrees',\n",
       " 'Depth km',\n",
       " 'Mag [+]',\n",
       " 'Region name [+]']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colm=[i.text.replace('\\n',' ') for i in col]\n",
    "colm=colm[1:7]\n",
    "colm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "values=driver.find_elements(By.TAG_NAME,'tr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2022-11-09',\n",
       "  '17:05:45.0',\n",
       "  '24min',\n",
       "  'ago',\n",
       "  '8.90',\n",
       "  'N',\n",
       "  '126.69',\n",
       "  'E',\n",
       "  '17',\n",
       "  '3.2',\n",
       "  'MINDANAO,',\n",
       "  'PHILIPPINES'],\n",
       " ['2022-11-09',\n",
       "  '16:58:17.0',\n",
       "  '31min',\n",
       "  'ago',\n",
       "  '17.95',\n",
       "  'N',\n",
       "  '66.91',\n",
       "  'W',\n",
       "  '10',\n",
       "  '2.5',\n",
       "  'PUERTO',\n",
       "  'RICO',\n",
       "  'REGION'],\n",
       " ['2022-11-09',\n",
       "  '16:57:37.0',\n",
       "  '32min',\n",
       "  'ago',\n",
       "  '20.58',\n",
       "  'S',\n",
       "  '69.43',\n",
       "  'W',\n",
       "  '77',\n",
       "  '2.6',\n",
       "  'TARAPACA,',\n",
       "  'CHILE'],\n",
       " ['2022-11-09',\n",
       "  '16:57:20.7',\n",
       "  '32min',\n",
       "  'ago',\n",
       "  '38.09',\n",
       "  'S',\n",
       "  '176.65',\n",
       "  'E',\n",
       "  '5',\n",
       "  '3.0',\n",
       "  'NORTH',\n",
       "  'ISLAND',\n",
       "  'OF',\n",
       "  'NEW',\n",
       "  'ZEALAND'],\n",
       " ['2022-11-09',\n",
       "  '16:50:09.7',\n",
       "  '40min',\n",
       "  'ago',\n",
       "  '43.91',\n",
       "  'N',\n",
       "  '13.31',\n",
       "  'E',\n",
       "  '7',\n",
       "  '2.3',\n",
       "  'CENTRAL',\n",
       "  'ITALY'],\n",
       " ['2022-11-09',\n",
       "  '16:50:02.0',\n",
       "  '40min',\n",
       "  'ago',\n",
       "  '15.10',\n",
       "  'N',\n",
       "  '94.37',\n",
       "  'W',\n",
       "  '16',\n",
       "  '4.2',\n",
       "  'OFF',\n",
       "  'COAST',\n",
       "  'OF',\n",
       "  'CHIAPAS,',\n",
       "  'MEXICO'],\n",
       " ['2022-11-09',\n",
       "  '16:43:54.0',\n",
       "  '46min',\n",
       "  'ago',\n",
       "  '10.16',\n",
       "  'S',\n",
       "  '118.81',\n",
       "  'E',\n",
       "  '10',\n",
       "  '3.4',\n",
       "  'SOUTH',\n",
       "  'OF',\n",
       "  'SUMBAWA,',\n",
       "  'INDONESIA'],\n",
       " ['2022-11-09',\n",
       "  '16:41:19.4',\n",
       "  '48min',\n",
       "  'ago',\n",
       "  '19.18',\n",
       "  'N',\n",
       "  '155.49',\n",
       "  'W',\n",
       "  '36',\n",
       "  '2.2',\n",
       "  'ISLAND',\n",
       "  'OF',\n",
       "  'HAWAII,',\n",
       "  'HAWAII'],\n",
       " ['2022-11-09',\n",
       "  '16:38:20.0',\n",
       "  '51min',\n",
       "  'ago',\n",
       "  '10.13',\n",
       "  'S',\n",
       "  '118.82',\n",
       "  'E',\n",
       "  '10',\n",
       "  '3.4',\n",
       "  'SOUTH',\n",
       "  'OF',\n",
       "  'SUMBAWA,',\n",
       "  'INDONESIA'],\n",
       " ['2022-11-09',\n",
       "  '16:32:35.0',\n",
       "  '57min',\n",
       "  'ago',\n",
       "  '26.87',\n",
       "  'S',\n",
       "  '70.14',\n",
       "  'W',\n",
       "  '78',\n",
       "  '2.8',\n",
       "  'ATACAMA,',\n",
       "  'CHILE'],\n",
       " ['2022-11-09',\n",
       "  '16:10:36.3',\n",
       "  '1hr',\n",
       "  '19min',\n",
       "  'ago',\n",
       "  '43.95',\n",
       "  'N',\n",
       "  '13.29',\n",
       "  'E',\n",
       "  '2',\n",
       "  '2.5',\n",
       "  'CENTRAL',\n",
       "  'ITALY'],\n",
       " ['2022-11-09',\n",
       "  '16:07:15.2',\n",
       "  '1hr',\n",
       "  '22min',\n",
       "  'ago',\n",
       "  '34.55',\n",
       "  'N',\n",
       "  '23.87',\n",
       "  'E',\n",
       "  '21',\n",
       "  '2.7',\n",
       "  'CRETE,',\n",
       "  'GREECE'],\n",
       " ['2022-11-09',\n",
       "  '15:58:32.1',\n",
       "  '1hr',\n",
       "  '31min',\n",
       "  'ago',\n",
       "  '37.07',\n",
       "  'N',\n",
       "  '28.38',\n",
       "  'E',\n",
       "  '9',\n",
       "  '2.9',\n",
       "  'WESTERN',\n",
       "  'TURKEY'],\n",
       " ['2022-11-09',\n",
       "  '15:40:34.6',\n",
       "  '1hr',\n",
       "  '49min',\n",
       "  'ago',\n",
       "  '43.97',\n",
       "  'N',\n",
       "  '13.33',\n",
       "  'E',\n",
       "  '10',\n",
       "  '2.2',\n",
       "  'CENTRAL',\n",
       "  'ITALY'],\n",
       " ['2022-11-09',\n",
       "  '15:37:05.0',\n",
       "  '1hr',\n",
       "  '53min',\n",
       "  'ago',\n",
       "  '21.53',\n",
       "  'S',\n",
       "  '68.57',\n",
       "  'W',\n",
       "  '115',\n",
       "  '2.9',\n",
       "  'ANTOFAGASTA,',\n",
       "  'CHILE'],\n",
       " ['2022-11-09',\n",
       "  '15:26:21.9',\n",
       "  '2hr',\n",
       "  '03min',\n",
       "  'ago',\n",
       "  '44.01',\n",
       "  'N',\n",
       "  '13.28',\n",
       "  'E',\n",
       "  '26',\n",
       "  '2.4',\n",
       "  'ADRIATIC',\n",
       "  'SEA'],\n",
       " ['2022-11-09',\n",
       "  '15:23:39.1',\n",
       "  '2hr',\n",
       "  '06min',\n",
       "  'ago',\n",
       "  '44.00',\n",
       "  'N',\n",
       "  '13.30',\n",
       "  'E',\n",
       "  '9',\n",
       "  '2.2',\n",
       "  'ADRIATIC',\n",
       "  'SEA'],\n",
       " ['2022-11-09',\n",
       "  '15:06:55.0',\n",
       "  '2hr',\n",
       "  '23min',\n",
       "  'ago',\n",
       "  '12.70',\n",
       "  'N',\n",
       "  '88.19',\n",
       "  'W',\n",
       "  '33',\n",
       "  '2.6',\n",
       "  'OFFSHORE',\n",
       "  'EL',\n",
       "  'SALVADOR'],\n",
       " ['2022-11-09',\n",
       "  '14:58:24.0',\n",
       "  '2hr',\n",
       "  '31min',\n",
       "  'ago',\n",
       "  '17.32',\n",
       "  'N',\n",
       "  '100.83',\n",
       "  'W',\n",
       "  '12',\n",
       "  '4.3',\n",
       "  'GUERRERO,',\n",
       "  'MEXICO'],\n",
       " ['2022-11-09',\n",
       "  '14:51:54.6',\n",
       "  '2hr',\n",
       "  '38min',\n",
       "  'ago',\n",
       "  '35.91',\n",
       "  'N',\n",
       "  '90.01',\n",
       "  'W',\n",
       "  '7',\n",
       "  '2.4',\n",
       "  'ARKANSAS'],\n",
       " ['2022-11-09',\n",
       "  '14:47:27.1',\n",
       "  '2hr',\n",
       "  '42min',\n",
       "  'ago',\n",
       "  '43.92',\n",
       "  'N',\n",
       "  '13.26',\n",
       "  'E',\n",
       "  '13',\n",
       "  '2.3',\n",
       "  'CENTRAL',\n",
       "  'ITALY'],\n",
       " ['2022-11-09',\n",
       "  '14:10:53.7',\n",
       "  '3hr',\n",
       "  '19min',\n",
       "  'ago',\n",
       "  '35.91',\n",
       "  'N',\n",
       "  '117.71',\n",
       "  'W',\n",
       "  '2',\n",
       "  '2.1',\n",
       "  'CENTRAL',\n",
       "  'CALIFORNIA'],\n",
       " ['2022-11-09',\n",
       "  '13:54:07.6',\n",
       "  '3hr',\n",
       "  '36min',\n",
       "  'ago',\n",
       "  '43.95',\n",
       "  'N',\n",
       "  '13.29',\n",
       "  'E',\n",
       "  '10',\n",
       "  '2.0',\n",
       "  'CENTRAL',\n",
       "  'ITALY'],\n",
       " ['2022-11-09',\n",
       "  '13:48:48.8',\n",
       "  '3hr',\n",
       "  '41min',\n",
       "  'ago',\n",
       "  '40.16',\n",
       "  'N',\n",
       "  '119.14',\n",
       "  'W',\n",
       "  '8',\n",
       "  '2.6',\n",
       "  'NEVADA'],\n",
       " ['2022-11-09',\n",
       "  '13:41:43.0',\n",
       "  '3hr',\n",
       "  '48min',\n",
       "  'ago',\n",
       "  '3.02',\n",
       "  'S',\n",
       "  '122.04',\n",
       "  'E',\n",
       "  '10',\n",
       "  '3.1',\n",
       "  'SULAWESI,',\n",
       "  'INDONESIA'],\n",
       " ['2022-11-09',\n",
       "  '13:37:46.8',\n",
       "  '3hr',\n",
       "  '52min',\n",
       "  'ago',\n",
       "  '43.95',\n",
       "  'N',\n",
       "  '13.31',\n",
       "  'E',\n",
       "  '9',\n",
       "  '2.6',\n",
       "  'CENTRAL',\n",
       "  'ITALY'],\n",
       " ['2022-11-09',\n",
       "  '13:34:23.2',\n",
       "  '3hr',\n",
       "  '55min',\n",
       "  'ago',\n",
       "  '43.95',\n",
       "  'N',\n",
       "  '13.36',\n",
       "  'E',\n",
       "  '7',\n",
       "  '2.2',\n",
       "  'CENTRAL',\n",
       "  'ITALY'],\n",
       " ['2022-11-09',\n",
       "  '13:34:05.0',\n",
       "  '3hr',\n",
       "  '56min',\n",
       "  'ago',\n",
       "  '64.02',\n",
       "  'N',\n",
       "  '21.35',\n",
       "  'W',\n",
       "  '5',\n",
       "  '3.2',\n",
       "  'ICELAND'],\n",
       " ['2022-11-09',\n",
       "  '13:21:37.0',\n",
       "  '4hr',\n",
       "  '08min',\n",
       "  'ago',\n",
       "  '27.89',\n",
       "  'S',\n",
       "  '66.75',\n",
       "  'W',\n",
       "  '182',\n",
       "  '3.1',\n",
       "  'CATAMARCA,',\n",
       "  'ARGENTINA'],\n",
       " ['2022-11-09',\n",
       "  '13:19:03.0',\n",
       "  '4hr',\n",
       "  '11min',\n",
       "  'ago',\n",
       "  '11.55',\n",
       "  'N',\n",
       "  '87.48',\n",
       "  'W',\n",
       "  '30',\n",
       "  '3.0',\n",
       "  'NEAR',\n",
       "  'COAST',\n",
       "  'OF',\n",
       "  'NICARAGUA'],\n",
       " ['2022-11-09',\n",
       "  '13:16:24.1',\n",
       "  '4hr',\n",
       "  '13min',\n",
       "  'ago',\n",
       "  '45.65',\n",
       "  'N',\n",
       "  '26.61',\n",
       "  'E',\n",
       "  '82',\n",
       "  '2.8',\n",
       "  'ROMANIA'],\n",
       " ['2022-11-09',\n",
       "  '13:08:41.0',\n",
       "  '4hr',\n",
       "  '21min',\n",
       "  'ago',\n",
       "  '18.88',\n",
       "  'N',\n",
       "  '121.95',\n",
       "  'E',\n",
       "  '113',\n",
       "  '3.2',\n",
       "  'LUZON,',\n",
       "  'PHILIPPINES'],\n",
       " ['2022-11-09',\n",
       "  '13:08:02.0',\n",
       "  '4hr',\n",
       "  '22min',\n",
       "  'ago',\n",
       "  '22.20',\n",
       "  'S',\n",
       "  '68.71',\n",
       "  'W',\n",
       "  '112',\n",
       "  '2.8',\n",
       "  'ANTOFAGASTA,',\n",
       "  'CHILE'],\n",
       " ['2022-11-09',\n",
       "  '13:00:04.7',\n",
       "  '4hr',\n",
       "  '30min',\n",
       "  'ago',\n",
       "  '19.38',\n",
       "  'N',\n",
       "  '66.34',\n",
       "  'W',\n",
       "  '11',\n",
       "  '3.6',\n",
       "  'PUERTO',\n",
       "  'RICO',\n",
       "  'REGION'],\n",
       " ['2022-11-09',\n",
       "  '12:54:30.9',\n",
       "  '4hr',\n",
       "  '35min',\n",
       "  'ago',\n",
       "  '58.51',\n",
       "  'N',\n",
       "  '152.25',\n",
       "  'W',\n",
       "  '35',\n",
       "  '2.6',\n",
       "  'KODIAK',\n",
       "  'ISLAND',\n",
       "  'REGION,',\n",
       "  'ALASKA'],\n",
       " ['2022-11-09',\n",
       "  '12:52:25.0',\n",
       "  '4hr',\n",
       "  '37min',\n",
       "  'ago',\n",
       "  '1.67',\n",
       "  'N',\n",
       "  '127.04',\n",
       "  'E',\n",
       "  '27',\n",
       "  '4.3',\n",
       "  'HALMAHERA,',\n",
       "  'INDONESIA'],\n",
       " ['2022-11-09',\n",
       "  '12:51:38.5',\n",
       "  '4hr',\n",
       "  '38min',\n",
       "  'ago',\n",
       "  '49.32',\n",
       "  'N',\n",
       "  '156.05',\n",
       "  'E',\n",
       "  '50',\n",
       "  '4.4',\n",
       "  'KURIL',\n",
       "  'ISLANDS'],\n",
       " ['2022-11-09',\n",
       "  '12:45:59.0',\n",
       "  '4hr',\n",
       "  '44min',\n",
       "  'ago',\n",
       "  '27.80',\n",
       "  'S',\n",
       "  '71.24',\n",
       "  'W',\n",
       "  '11',\n",
       "  '2.8',\n",
       "  'OFFSHORE',\n",
       "  'ATACAMA,',\n",
       "  'CHILE'],\n",
       " ['2022-11-09',\n",
       "  '12:44:13.5',\n",
       "  '4hr',\n",
       "  '45min',\n",
       "  'ago',\n",
       "  '43.98',\n",
       "  'N',\n",
       "  '13.27',\n",
       "  'E',\n",
       "  '10',\n",
       "  '2.4',\n",
       "  'CENTRAL',\n",
       "  'ITALY'],\n",
       " ['2022-11-09',\n",
       "  '12:33:52.0',\n",
       "  '4hr',\n",
       "  '56min',\n",
       "  'ago',\n",
       "  '43.90',\n",
       "  'N',\n",
       "  '13.39',\n",
       "  'E',\n",
       "  '8',\n",
       "  '2.3',\n",
       "  'CENTRAL',\n",
       "  'ITALY'],\n",
       " ['2022-11-09',\n",
       "  '12:29:54.0',\n",
       "  '5hr',\n",
       "  '00min',\n",
       "  'ago',\n",
       "  '33.05',\n",
       "  'S',\n",
       "  '68.16',\n",
       "  'W',\n",
       "  '10',\n",
       "  '3.1',\n",
       "  'MENDOZA,',\n",
       "  'ARGENTINA'],\n",
       " ['2022-11-09',\n",
       "  '12:20:59.8',\n",
       "  '5hr',\n",
       "  '09min',\n",
       "  'ago',\n",
       "  '43.96',\n",
       "  'N',\n",
       "  '13.33',\n",
       "  'E',\n",
       "  '9',\n",
       "  '2.0',\n",
       "  'CENTRAL',\n",
       "  'ITALY'],\n",
       " ['2022-11-09',\n",
       "  '12:13:03.6',\n",
       "  '5hr',\n",
       "  '17min',\n",
       "  'ago',\n",
       "  '43.95',\n",
       "  'N',\n",
       "  '13.32',\n",
       "  'E',\n",
       "  '10',\n",
       "  '2.2',\n",
       "  'CENTRAL',\n",
       "  'ITALY'],\n",
       " ['2022-11-09',\n",
       "  '12:10:37.9',\n",
       "  '5hr',\n",
       "  '19min',\n",
       "  'ago',\n",
       "  '19.16',\n",
       "  'N',\n",
       "  '155.38',\n",
       "  'W',\n",
       "  '36',\n",
       "  '2.6',\n",
       "  'ISLAND',\n",
       "  'OF',\n",
       "  'HAWAII,',\n",
       "  'HAWAII'],\n",
       " ['6',\n",
       "  'III',\n",
       "  '2022-11-09',\n",
       "  '12:10:05.4',\n",
       "  '5hr',\n",
       "  '20min',\n",
       "  'ago',\n",
       "  '44.05',\n",
       "  'N',\n",
       "  '13.31',\n",
       "  'E',\n",
       "  '26',\n",
       "  '3.9',\n",
       "  'ADRIATIC',\n",
       "  'SEA'],\n",
       " ['2022-11-09',\n",
       "  '12:02:56.2',\n",
       "  '5hr',\n",
       "  '27min',\n",
       "  'ago',\n",
       "  '44.01',\n",
       "  'N',\n",
       "  '13.27',\n",
       "  'E',\n",
       "  '8',\n",
       "  '3.1',\n",
       "  'ADRIATIC',\n",
       "  'SEA'],\n",
       " ['2022-11-09',\n",
       "  '11:50:55.0',\n",
       "  '5hr',\n",
       "  '39min',\n",
       "  'ago',\n",
       "  '8.40',\n",
       "  'S',\n",
       "  '119.82',\n",
       "  'E',\n",
       "  '142',\n",
       "  '3.2',\n",
       "  'FLORES',\n",
       "  'REGION,',\n",
       "  'INDONESIA'],\n",
       " ['2022-11-09',\n",
       "  '11:46:06.2',\n",
       "  '5hr',\n",
       "  '44min',\n",
       "  'ago',\n",
       "  '19.10',\n",
       "  'N',\n",
       "  '155.42',\n",
       "  'W',\n",
       "  '30',\n",
       "  '2.0',\n",
       "  'ISLAND',\n",
       "  'OF',\n",
       "  'HAWAII,',\n",
       "  'HAWAII'],\n",
       " ['2022-11-09',\n",
       "  '11:41:07.0',\n",
       "  '5hr',\n",
       "  '49min',\n",
       "  'ago',\n",
       "  '2.98',\n",
       "  'S',\n",
       "  '140.05',\n",
       "  'E',\n",
       "  '16',\n",
       "  '2.7',\n",
       "  'NEAR',\n",
       "  'N',\n",
       "  'COAST',\n",
       "  'OF',\n",
       "  'PAPUA,',\n",
       "  'INDONESIA']]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val=[e.text.strip().split() for e in values]\n",
    "val=val[15:64]\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['invoice' 'client' 'units'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2z/3qxl1g8j49s520l3b9w9y4hr0000gn/T/ipykernel_11089/1898690941.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'invoice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'client'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'units'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/clase/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/clase/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4911\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4912\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4913\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4914\u001b[0m         )\n\u001b[1;32m   4915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/clase/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4150\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/clase/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   4183\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4184\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4185\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4186\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/clase/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6015\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6017\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6019\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['invoice' 'client' 'units'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame(val)\n",
    "df=df.drop(['invoice', 'client', 'units'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count number of tweets by a given Twitter account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** for account names not found. \n",
    "<br>***Hint:*** the program should count the number of tweets for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/AOC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(PATH)\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'14,3 mil Tweets'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tw=driver.find_element(By.XPATH,'//*[@id=\"react-root\"]/div/div/div[2]/main/div/div/div/div/div/div[1]/div[1]/div/div/div/div/div/div[2]/div/div').text\n",
    "n_tw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of followers of a given twitter account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** in case account/s name not found. \n",
    "<br>***Hint:*** the program should count the followers for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/AOC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(PATH)\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'13,4 M'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_foll=driver.find_element(By.XPATH,'//*[@id=\"react-root\"]/div/div/div[2]/main/div/div/div/div/div/div[3]/div/div/div/div/div[5]/div[2]/a/span[1]/span').text\n",
    "n_foll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all language names and number of related articles in the order they appear in wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.wikipedia.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(PATH)\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"83e6b1e50aeb9bfa8a9fd4e67de4e377\", element=\"1902e0c8-d98e-4b74-af9d-fbfc75e2d115\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"83e6b1e50aeb9bfa8a9fd4e67de4e377\", element=\"f402bb27-f769-464c-b189-d3cccc4b0b6b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"83e6b1e50aeb9bfa8a9fd4e67de4e377\", element=\"29e99911-c58f-4e59-a95d-845f9734dd91\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"83e6b1e50aeb9bfa8a9fd4e67de4e377\", element=\"598fca9c-dacc-43e4-8031-35090be282e0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"83e6b1e50aeb9bfa8a9fd4e67de4e377\", element=\"a2de9b0f-f841-42c0-9ce0-296384885fd1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"83e6b1e50aeb9bfa8a9fd4e67de4e377\", element=\"2daad9c7-fd0e-4593-bfe7-754f3592794c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"83e6b1e50aeb9bfa8a9fd4e67de4e377\", element=\"624b8b70-3f77-4cf8-96c9-420c2ac32e62\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"83e6b1e50aeb9bfa8a9fd4e67de4e377\", element=\"418e1e61-f592-4464-8651-725056615ce8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"83e6b1e50aeb9bfa8a9fd4e67de4e377\", element=\"9a9ca1d3-4ff1-490e-8cec-3e8ecbad8cc6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"83e6b1e50aeb9bfa8a9fd4e67de4e377\", element=\"2fd9a5bb-f8be-4ae6-860a-465969aec2de\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"83e6b1e50aeb9bfa8a9fd4e67de4e377\", element=\"0335fb0a-866b-453d-ba58-919ddf11b03b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"83e6b1e50aeb9bfa8a9fd4e67de4e377\", element=\"6d779624-f053-4282-ad74-66c0d058760c\")>]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box=driver.find_elements(By.TAG_NAME,'strong')\n",
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Español',\n",
       " 'English',\n",
       " '日本語',\n",
       " 'Русский',\n",
       " 'Français',\n",
       " 'Deutsch',\n",
       " 'Italiano',\n",
       " '中文',\n",
       " 'Português']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages=[e.text for e in box]\n",
    "languages[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list with the different kind of datasets available in data.gov.uk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://data.gov.uk/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(PATH)\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "link=driver.find_elements(By.CLASS_NAME,'govuk-link')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Business and economy',\n",
       " 'Crime and justice',\n",
       " 'Defence',\n",
       " 'Education',\n",
       " 'Environment',\n",
       " 'Government',\n",
       " 'Government spending',\n",
       " 'Health',\n",
       " 'Mapping',\n",
       " 'Society',\n",
       " 'Towns and cities',\n",
       " 'Transport',\n",
       " 'Digital service performance',\n",
       " 'Government reference data']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "govuk=[e.text for e in link]\n",
    "govuk[4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 languages by number of native speakers stored in a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(PATH)\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla=driver.find_elements(By.CLASS_NAME,'mw-redirect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mandarin Chinese',\n",
       " 'Spanish',\n",
       " 'English',\n",
       " 'Hindi',\n",
       " 'Bengali',\n",
       " 'Portuguese',\n",
       " 'Russian',\n",
       " 'Japanese',\n",
       " 'Yue Chinese',\n",
       " 'Vietnamese']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T10=[e.text for e in tabla]\n",
    "T10[7:17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape a certain number of tweets of a given Twitter account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDB's Top 250 data (movie name, Initial release, director name and stars) as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "url = 'https://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movie name, year and a brief summary of the top 10 random movies (IMDB) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the url you will scrape in this exercise\n",
    "url = 'http://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the live weather report (temperature, wind speed, description and weather) of a given city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://openweathermap.org/current\n",
    "city = city=input('Enter the city:')\n",
    "url = 'http://api.openweathermap.org/data/2.5/weather?'+'q='+city+'&APPID=b35975e18dc93725acb092f7272cc6b8&units=metric'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Book name,price and stock availability as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise. \n",
    "# It is a fictional bookstore created to be scraped. \n",
    "url = 'http://books.toscrape.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
